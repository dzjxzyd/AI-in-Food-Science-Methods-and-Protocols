{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfX9Rn-DMcg2"
      },
      "source": [
        "### Load necessary packages & define device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JKrXq9EXcQMx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Huggingface datasets and tokenizers\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Split\n",
        "\n",
        "import random\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFJb6xaPMc3Q",
        "outputId": "a4102ba8-8605-4281-bc6d-58ea6c295926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Device name: NVIDIA RTX A5000\n",
            "Device memory: 23.547119140625 GB\n"
          ]
        }
      ],
      "source": [
        "# Define the device (accelerate the training process)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_built() or torch.backends.mps.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "if (device == 'cuda'):\n",
        "    print(f\"Device name: {torch.cuda.get_device_name(device.index)}\")\n",
        "    print(f\"Device memory: {torch.cuda.get_device_properties(device.index).total_memory / 1024 ** 3} GB\")\n",
        "elif (device == 'mps'):\n",
        "    print(f\"Device name: <mps>\")\n",
        "else:\n",
        "    print(\"NOTE: If you have a GPU, consider using it for training.\")\n",
        "    print(\"      On a Windows machine with NVidia GPU, check this video: https://www.youtube.com/watch?v=GMSjDTU8Zlc\")\n",
        "    print(\"      On a Mac machine, run: pip3 install --pre torch torchvision torchaudio torchtext --index-url https://download.pytorch.org/whl/nightly/cpu\")\n",
        "device = torch.device(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaUIYU0RJY0r"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Raw Data Loading, Tokenizer Construction, and Dataset Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPvJvTuTMAM4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ],
      "source": [
        "# Load dataset from Hugging Face (dzjxzyd/UniRef50_len_0_50); replace it as the path of your customed dataset\n",
        "# If no custom split is defined during upload, all data are stored in the 'train' split by default\n",
        "# Select the column of interest ('Reference sequence') and convert it to a list\n",
        "ds_raw = load_dataset('dzjxzyd/UniRef50_len_0_50', split='train')['Reference sequence']# only need the sequence -output is a list\n",
        "# Dataset division, 0.5 % as the validation dataset\n",
        "val_ds_size = int(0.005* len(ds_raw))\n",
        "train_ds_size  = len(ds_raw) - val_ds_size\n",
        "train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bs3urp_pdpYv"
      },
      "outputs": [],
      "source": [
        "def build_tokenizer(ds):\n",
        "    # Initialize a WordLevel tokenizer with [UNK] as the unknown token\n",
        "    tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
        "    # Pre-tokenizer/preprocessing: split text(peptide sequences) into individual characters\n",
        "    # (pattern='' + behavior='isolated' means every character is treated as a separate token)\n",
        "    tokenizer.pre_tokenizer = Split(pattern='', behavior='isolated')\n",
        "    # Define a trainer: 1. includes special tokens; 2. ignores tokens with frequency < 2\n",
        "    trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\",\"[MASK]\"], min_frequency=2)\n",
        "    # Train tokenizer on the dataset (ds should be an iterable/list of sequences)\n",
        "    tokenizer.train_from_iterator(ds, trainer=trainer)\n",
        "    # Save the trained tokenizer to file for reuse\n",
        "    tokenizer.save('tokenizer.json')\n",
        "    return tokenizer\n",
        "# Build tokenizers\n",
        "tokenizer = build_tokenizer(train_ds_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom dataset class for peptide sequences\n",
        "class PeptideDataset(Dataset):\n",
        "    def __init__(self, ds, tokenizer, seq_len):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            ds (list): List of raw peptide sequences.\n",
        "            tokenizer: A tokenizer object that can map characters/tokens to IDs.\n",
        "            seq_len (int): Fixed sequence length for model input (after padding).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.ds = ds\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        # Define special tokens (convert them into tensor form)\n",
        "        self.sos_token = torch.tensor([tokenizer.token_to_id(\"[SOS]\")], dtype=torch.int64)  # Start of sequence\n",
        "        self.eos_token = torch.tensor([tokenizer.token_to_id(\"[EOS]\")], dtype=torch.int64)  # End of sequence\n",
        "        self.pad_token = torch.tensor([tokenizer.token_to_id(\"[PAD]\")], dtype=torch.int64)  # Padding\n",
        "        self.mask_token = torch.tensor([tokenizer.token_to_id(\"[MASK]\")], dtype=torch.int64) # Mask (for MLM)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return total number of sequences in the dataset\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieve one sequence, apply random masking, \n",
        "        then build encoder_input and label tensors with special tokens + padding.\n",
        "        \"\"\"\n",
        "        seq = self.ds[idx]  # Get raw sequence\n",
        "\n",
        "        # Apply masking strategy (15% replaced with [MASK]) \n",
        "        # Returns both masked sequence IDs and the original token IDs\n",
        "        masked_seq_ids, origi_seq_ids = random_mask(seq, self.tokenizer)\n",
        "\n",
        "        # Compute how many [PAD] tokens are needed after adding [SOS] and [EOS]\n",
        "        num_padding_tokens = self.seq_len - len(masked_seq_ids) - 2  \n",
        "        if num_padding_tokens < 0:\n",
        "            raise ValueError(\"Sequence is too long for the specified seq_len\")\n",
        "\n",
        "        # Build encoder input: [SOS] + masked sequence + [EOS] + [PAD...]\n",
        "        encoder_input = torch.cat(\n",
        "            [\n",
        "                self.sos_token,\n",
        "                torch.tensor(masked_seq_ids, dtype=torch.int64),\n",
        "                self.eos_token,\n",
        "                torch.tensor([self.pad_token] * num_padding_tokens, dtype=torch.int64),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "        # Build label: [SOS] + original sequence + [EOS] + [PAD...]\n",
        "        # (the model should learn to predict original tokens from masked input)\n",
        "        label = torch.cat(\n",
        "            [\n",
        "                self.sos_token,\n",
        "                torch.tensor(origi_seq_ids, dtype=torch.int64),\n",
        "                self.eos_token,\n",
        "                torch.tensor([self.pad_token] * num_padding_tokens, dtype=torch.int64),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "        # Sanity check: ensure both sequences have fixed length = seq_len\n",
        "        assert encoder_input.size(0) == self.seq_len, \"encoder_input size mismatch\"\n",
        "        assert label.size(0) == self.seq_len, \"label size mismatch\"\n",
        "        return {\n",
        "            \"encoder_input\": encoder_input,  \n",
        "            # Shape: (seq_len). Model input sequence with masked tokens and padding.\n",
        "\n",
        "            # \"encoder_mask\": (encoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int(),  \n",
        "            \"encoder_mask\": (encoder_input == self.pad_token).bool(),  \n",
        "            # Shape: (1, 1, seq_len). Attention mask where 1 = valid token, 0 = pad.\n",
        "            # Two unsqueezes are added to match transformer attention dimensions.\n",
        "\n",
        "            \"label\": label  \n",
        "            # Shape: (seq_len). Original sequence (target labels for MLM).\n",
        "        }\n",
        "# Helper function to apply random token masking (like BERT MLM)\n",
        "def random_mask(sentence, tokenizer):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        sentence (str): Raw sequence (string of characters).\n",
        "        tokenizer: Tokenizer to map characters to IDs.\n",
        "\n",
        "    Returns:\n",
        "        masked_seq_ids (list of int): Sequence IDs with 15% tokens replaced by [MASK].\n",
        "        origi_seq_ids (list of int): Original unmasked sequence IDs.\n",
        "    \"\"\"\n",
        "    masked_seq_ids = []\n",
        "    # Apply masking: each character has a 15% chance of being replaced by [MASK]\n",
        "    for token in sentence:\n",
        "        prob = random.random()\n",
        "        if prob <= 0.15:\n",
        "            masked_seq_ids.append(tokenizer.token_to_id(\"[MASK]\"))  # Replace with [MASK]\n",
        "        else: \n",
        "            masked_seq_ids.append(tokenizer.encode(token).ids[0])   # Keep original token ID\n",
        "\n",
        "    # Encode the original sequence fully (without masking)\n",
        "    origi_seq_ids = tokenizer.encode(sentence).ids  \n",
        "\n",
        "    # Sanity check: both masked and original sequences must have same length\n",
        "    assert len(masked_seq_ids) == len(origi_seq_ids), \\\n",
        "        \"Masked sequence length does not match original sequence length\"\n",
        "\n",
        "    return masked_seq_ids, origi_seq_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCCCYkrHMbI8"
      },
      "outputs": [],
      "source": [
        "# ===== Define maximum sequence length =====\n",
        "# The maximum peptide length is set to 50 residues. With the addition of [SOS] and [EOS],\n",
        "# the total sequence length becomes 52 tokens. This value ensures that all sequences\n",
        "# are padded or truncated to a fixed dimension.\n",
        "seq_len = 52  \n",
        "\n",
        "# ===== Construct Dataset objects =====\n",
        "# PeptideDataset applies tokenization, special token insertion ([SOS], [EOS], [PAD]),\n",
        "# and random masking (for MLM pretraining). \n",
        "# - train_ds uses the training set of raw sequences\n",
        "# - val_ds uses the validation set of raw sequences\n",
        "train_ds = PeptideDataset(train_ds_raw, tokenizer, seq_len)\n",
        "val_ds   = PeptideDataset(val_ds_raw, tokenizer, seq_len)\n",
        "\n",
        "# ===== Wrap Dataset with DataLoader =====\n",
        "# DataLoader handles batching and shuffling, making it easier to feed data into the model.\n",
        "# - Training dataloader: batch_size=2000, with shuffling enabled to randomize batches each epoch\n",
        "# - Validation dataloader: batch_size=2000, with shuffling disabled to keep evaluation consistent\n",
        "train_dataloader = DataLoader(train_ds, batch_size=2000, shuffle=True)\n",
        "val_dataloader   = DataLoader(val_ds,   batch_size=2000, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO2_2FEIJeRL"
      },
      "source": [
        "### Loading Raw Data and Build Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JPtdO7vJdw5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class SinusoidalPositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, max_len: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Create (max_len, d_model) positional encodings\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # (max_len, 1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)  # even indices\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)  # odd indices\n",
        "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
        "\n",
        "        self.register_buffer(\"pe\", pe)  # not learnable\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor of shape (batch, seq_len, d_model)\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:, :x.size(1), :].requires_grad_(False)\n",
        "        return self.dropout(x)\n",
        "\n",
        "class PepBERT(nn.Module):\n",
        "    def __init__(self, vocab_size, seq_len, pad_id, d_model=160, n_heads=8, n_layers=6, d_ff=640, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx = pad_id)\n",
        "\n",
        "        # fixed (sinusoidal) position encoding\n",
        "        self.pos_encoding = SinusoidalPositionalEncoding(d_model, seq_len, dropout)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=d_ff,\n",
        "            dropout=dropout,\n",
        "            batch_first=True  # Input shape: (batch, seq, d_model)\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "\n",
        "        # Output projection\n",
        "        self.proj = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, src, src_key_padding_mask=None):\n",
        "        \"\"\"\n",
        "        src: (batch, seq_len)\n",
        "        src_key_padding_mask: (batch, seq_len), True=PAD, False=real token\n",
        "        \"\"\"\n",
        "        x = self.embedding(src) * math.sqrt(self.embedding.embedding_dim)\n",
        "        x = self.pos_encoding(x)\n",
        "        x = self.encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "        return self.proj(x)  # (batch, seq_len, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "\n",
        "class SinusoidalPositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Fixed (non-learnable) sinusoidal positional encoding, as in\n",
        "    'Attention Is All You Need'. Precomputes a (max_len, d_model)\n",
        "    table and adds it to token embeddings at call time.\n",
        "\n",
        "    Args:\n",
        "        d_model: Embedding (model) dimension.\n",
        "        max_len: Maximum supported sequence length for precomputed table.\n",
        "        dropout: Dropout applied after adding positions.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int, max_len: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Precompute sinusoidal table: shape (max_len, d_model)\n",
        "        # pe[pos, 2i]   = sin(pos / (10000^(2i/d_model)))\n",
        "        # pe[pos, 2i+1] = cos(pos / (10000^(2i/d_model)))\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # (max_len, 1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2, dtype=torch.float) * (-math.log(10000.0) / d_model)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)  # even dimensions\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)  # odd  dimensions\n",
        "\n",
        "        # Add batch dim for broadcasting at runtime: (1, max_len, d_model)\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # Register as a buffer so it moves with .to(device) but is not a parameter\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Add positions to token embeddings.\n",
        "\n",
        "        Args:\n",
        "            x: Token embeddings, shape (B, S, D) = (batch, seq_len, d_model)\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape (B, S, D) with positions added, then dropout applied.\n",
        "        \"\"\"\n",
        "        # Slice the first S positions and add to x; no gradient through the table\n",
        "        x = x + self.pe[:, : x.size(1), :].requires_grad_(False)\n",
        "\n",
        "        # NOTE (optional): if you do NOT want to add positions to PAD rows,\n",
        "        # you can pass a (B, S) bool mask into forward and zero out pe on PAD:\n",
        "        # pe = self.pe[:, : x.size(1), :]\n",
        "        # pe = pe.masked_fill(key_padding_mask.unsqueeze(-1), 0.0)  # True=PAD\n",
        "        # x = x + pe\n",
        "\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class PepBERT(nn.Module):\n",
        "    \"\"\"\n",
        "    BERT-style Transformer encoder for sequences (e.g., peptides).\n",
        "\n",
        "    Components:\n",
        "        - Token embedding with a defined padding_idx (PAD rows are zero and not updated).\n",
        "        - Fixed sinusoidal positional encoding (added to token embeddings).\n",
        "        - Stack of nn.TransformerEncoderLayer blocks (self-attention + FFN).\n",
        "        - Linear projection to vocabulary size (for MLM-style training).\n",
        "\n",
        "    Args:\n",
        "        vocab_size: Size of the tokenizer vocabulary.\n",
        "        seq_len:    Max sequence length (drives positional table size).\n",
        "        pad_id:     Vocabulary ID used for PAD tokens.\n",
        "        d_model:    Embedding dimension.\n",
        "        n_heads:    Number of attention heads.\n",
        "        n_layers:   Number of encoder layers (depth).\n",
        "        d_ff:       Hidden size of the position-wise feed-forward (usually 4*d_model).\n",
        "        dropout:    Dropout probability used across the module.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        seq_len: int,\n",
        "        pad_id: int,\n",
        "        d_model: int = 160,\n",
        "        n_heads: int = 8,\n",
        "        n_layers: int = 6,\n",
        "        d_ff: int = 640,\n",
        "        dropout: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Token embedding: PAD rows are always zero and are excluded from updates\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=pad_id)\n",
        "\n",
        "        # Fixed positional encoding (sin/cos), shape added as (B, S, D)\n",
        "        self.pos_encoding = SinusoidalPositionalEncoding(d_model, seq_len, dropout)\n",
        "\n",
        "        # Transformer encoder stack (each layer: MHA + FFN + residual + LayerNorm)\n",
        "        # batch_first=True => inputs are (B, S, D)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=d_ff,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "\n",
        "        # Final projection to logits over vocabulary (for masked language modeling)\n",
        "        self.proj = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        src: torch.Tensor,\n",
        "        src_key_padding_mask: torch.Tensor | None = None,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Args:\n",
        "            src: LongTensor token IDs, shape (B, S).\n",
        "            src_key_padding_mask: BoolTensor, shape (B, S),\n",
        "                                    True at PAD positions (to be ignored by attention).\n",
        "\n",
        "        Returns:\n",
        "            Logits over vocabulary: shape (B, S, vocab_size).\n",
        "        \"\"\"\n",
        "        # Embed tokens and scale by sqrt(d_model) (stabilizes training as in the paper)\n",
        "        x = self.embedding(src) * math.sqrt(self.embedding.embedding_dim)  # (B, S, D)\n",
        "\n",
        "        # Add fixed sinusoidal positional encoding\n",
        "        x = self.pos_encoding(x)  # (B, S, D)\n",
        "\n",
        "        # IMPORTANT:\n",
        "        # - nn.TransformerEncoder expects src_key_padding_mask with shape (B, S), True=PAD.\n",
        "        # - On Apple Silicon (MPS), passing this mask may trigger a nested-tensor path\n",
        "        #   not fully implemented. If you ever hit NotImplementedError on MPS, you can:\n",
        "        #   (A) Drop the mask on MPS:\n",
        "        #       if x.device.type == \"mps\": src_key_padding_mask = None\n",
        "        #   (B) Or pass a dummy attn_mask to disable that fast-path while keeping padding mask:\n",
        "        #       S = x.size(1)\n",
        "        #       dummy = torch.zeros((S, S), dtype=torch.bool, device=x.device)\n",
        "        #       x = self.encoder(x, mask=dummy, src_key_padding_mask=src_key_padding_mask)\n",
        "        #       return self.proj(x)\n",
        "\n",
        "        x = self.encoder(x, src_key_padding_mask=src_key_padding_mask)  # (B, S, D)\n",
        "\n",
        "        # Project hidden states to vocabulary logits (use CrossEntropyLoss with ignore_index=pad_id)\n",
        "        return self.proj(x)  # (B, S, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== Define special token IDs =====\n",
        "pad_id  = tokenizer.token_to_id(\"[PAD]\")   # ID for [PAD] token (used for sequence padding)\n",
        "mask_id = tokenizer.token_to_id(\"[MASK]\")  # ID for [MASK] token (used in MLM objective)\n",
        "\n",
        "# ===== Define the model =====\n",
        "model = PepBERT(\n",
        "    vocab_size=tokenizer.get_vocab_size(),\n",
        "    seq_len=seq_len,\n",
        "    pad_id=tokenizer.token_to_id(\"[PAD]\"),\n",
        "    d_model=160,\n",
        "    n_heads=8,\n",
        "    n_layers=6,\n",
        "    d_ff=640,\n",
        "    dropout=0.0\n",
        ").to(device)\n",
        "\n",
        "# ===== Define optimizer =====\n",
        "# AdamW: widely used optimizer for Transformer models\n",
        "# - lr           : learning rate\n",
        "# - eps          : term added to denominator for numerical stability\n",
        "# - betas        : (β1, β2) coefficients for running averages of gradient and squared gradient\n",
        "# - weight_decay : L2 regularization to reduce overfitting\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=4e-4,\n",
        "    eps=1e-8,\n",
        "    betas=(0.9, 0.98),\n",
        "    weight_decay=0.01\n",
        ")\n",
        "\n",
        "# ===== Define loss function =====\n",
        "# CrossEntropyLoss computes negative log-likelihood over vocabulary.\n",
        "# - ignore_index : excludes [PAD] tokens from loss computation\n",
        "# - reduction    : here set to \"sum\" so loss can later be normalized\n",
        "#                  by the number of masked tokens (MLM objective)\n",
        "loss_fn = nn.CrossEntropyLoss(\n",
        "    ignore_index=pad_id,\n",
        "    reduction=\"sum\"\n",
        ").to(device)\n",
        "\n",
        "# NOTE:\n",
        "# For masked language modeling (MLM), the average loss per masked token\n",
        "# is computed as: (sum of losses over all masked tokens) / (number of masked tokens)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_validation(model, val_dataloader, tokenizer, device, loss_fn, mask_id):\n",
        "    model.eval().to(device)\n",
        "    total_loss, total_masked = 0.0, 0\n",
        "    V = tokenizer.get_vocab_size()\n",
        "    # ===== Define special token IDs =====\n",
        "    mask_id = tokenizer.token_to_id(\"[MASK]\")  # ID for [MASK] token (used in MLM objective)\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            encoder_input = batch[\"encoder_input\"].to(device)   # (B, S)\n",
        "            encoder_mask  = batch[\"encoder_mask\"].to(device)    # (B, S), True=PAD\n",
        "            labels        = batch[\"label\"].to(device)           # (B, S)\n",
        "\n",
        "            logits = model(encoder_input, src_key_padding_mask=encoder_mask)  # (B, S, V)\n",
        "\n",
        "            masked_pos = (encoder_input == mask_id)             # (B, S)\n",
        "            num_masked = int(masked_pos.sum().item())\n",
        "            if num_masked == 0:\n",
        "                continue  # nothing to average for this batch\n",
        "\n",
        "            logits_flat = logits.view(-1, V)\n",
        "            labels_flat = labels.view(-1)\n",
        "            masked_idx  = masked_pos.view(-1)\n",
        "\n",
        "            loss = loss_fn(logits_flat[masked_idx], labels_flat[masked_idx])  # sum over masked\n",
        "\n",
        "            total_loss   += loss.item()\n",
        "            total_masked += num_masked\n",
        "\n",
        "    return total_loss / max(total_masked, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 00: 100%|██████████| 981/981 [09:45<00:00,  1.68it/s, loss=2.8095]\n",
            "/hpc/group/youlab/zd75/envs/pubgo/lib/python3.11/site-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  output = torch._nested_tensor_from_mask(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00: train loss = 2.8267, val loss = 2.8010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 01: 100%|██████████| 981/981 [09:40<00:00,  1.69it/s, loss=2.8027]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01: train loss = 2.7963, val loss = 2.7962\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 02: 100%|██████████| 981/981 [09:35<00:00,  1.71it/s, loss=2.7888]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 02: train loss = 2.7940, val loss = 2.7946\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 03: 100%|██████████| 981/981 [09:33<00:00,  1.71it/s, loss=2.7700]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 03: train loss = 2.7909, val loss = 2.7859\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 04: 100%|██████████| 981/981 [09:32<00:00,  1.71it/s, loss=2.7668]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 04: train loss = 2.7828, val loss = 2.7861\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 05: 100%|██████████| 981/981 [09:33<00:00,  1.71it/s, loss=2.7852]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 05: train loss = 2.7792, val loss = 2.7811\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 06: 100%|██████████| 981/981 [09:32<00:00,  1.71it/s, loss=2.7950]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 06: train loss = 2.7774, val loss = 2.7843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 07: 100%|██████████| 981/981 [09:30<00:00,  1.72it/s, loss=2.7685]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 07: train loss = 2.7755, val loss = 2.7748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 08: 100%|██████████| 981/981 [09:34<00:00,  1.71it/s, loss=2.7691]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 08: train loss = 2.7747, val loss = 2.7744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 09: 100%|██████████| 981/981 [09:34<00:00,  1.71it/s, loss=2.7708]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 09: train loss = 2.7729, val loss = 2.7758\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 10: 100%|██████████| 981/981 [09:33<00:00,  1.71it/s, loss=2.7496]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: train loss = 2.7718, val loss = 2.7771\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 11: 100%|██████████| 981/981 [09:34<00:00,  1.71it/s, loss=2.7795]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: train loss = 2.7707, val loss = 2.7718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 12: 100%|██████████| 981/981 [09:35<00:00,  1.70it/s, loss=2.7753]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: train loss = 2.7695, val loss = 2.7731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 13: 100%|██████████| 981/981 [10:15<00:00,  1.59it/s, loss=2.7672]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: train loss = 2.7680, val loss = 2.7665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 14: 100%|██████████| 981/981 [10:12<00:00,  1.60it/s, loss=2.7611]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: train loss = 2.7673, val loss = 2.7740\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 15: 100%|██████████| 981/981 [10:17<00:00,  1.59it/s, loss=2.7552]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: train loss = 2.7663, val loss = 2.7702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 16: 100%|██████████| 981/981 [10:18<00:00,  1.59it/s, loss=2.7575]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: train loss = 2.7652, val loss = 2.7664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 17: 100%|██████████| 981/981 [10:17<00:00,  1.59it/s, loss=2.7597]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: train loss = 2.7643, val loss = 2.7681\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 18: 100%|██████████| 981/981 [10:16<00:00,  1.59it/s, loss=2.7686]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18: train loss = 2.7634, val loss = 2.7661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 19: 100%|██████████| 981/981 [10:17<00:00,  1.59it/s, loss=2.7653]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19: train loss = 2.7622, val loss = 2.7660\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 20: 100%|██████████| 981/981 [10:16<00:00,  1.59it/s, loss=2.7569]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20: train loss = 2.7611, val loss = 2.7651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 21: 100%|██████████| 981/981 [10:12<00:00,  1.60it/s, loss=2.7768]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21: train loss = 2.7602, val loss = 2.7649\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 22: 100%|██████████| 981/981 [10:14<00:00,  1.60it/s, loss=2.7603]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22: train loss = 2.7597, val loss = 2.7656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 23: 100%|██████████| 981/981 [10:13<00:00,  1.60it/s, loss=2.7678]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23: train loss = 2.7584, val loss = 2.7639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 24: 100%|██████████| 981/981 [10:14<00:00,  1.60it/s, loss=2.7476]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24: train loss = 2.7577, val loss = 2.7583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 25: 100%|██████████| 981/981 [10:15<00:00,  1.59it/s, loss=2.7653]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25: train loss = 2.7572, val loss = 2.7601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 26: 100%|██████████| 981/981 [10:17<00:00,  1.59it/s, loss=2.7453]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26: train loss = 2.7562, val loss = 2.7594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 27: 100%|██████████| 981/981 [10:14<00:00,  1.60it/s, loss=2.7687]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27: train loss = 2.7555, val loss = 2.7575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 28: 100%|██████████| 981/981 [10:14<00:00,  1.60it/s, loss=2.7453]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28: train loss = 2.7546, val loss = 2.7578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 29: 100%|██████████| 981/981 [10:16<00:00,  1.59it/s, loss=2.7314]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29: train loss = 2.7533, val loss = 2.7550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 30: 100%|██████████| 981/981 [10:16<00:00,  1.59it/s, loss=2.7537]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30: train loss = 2.7527, val loss = 2.7578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 31: 100%|██████████| 981/981 [10:15<00:00,  1.59it/s, loss=2.7741]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31: train loss = 2.7515, val loss = 2.7521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 32: 100%|██████████| 981/981 [10:15<00:00,  1.59it/s, loss=2.7667]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32: train loss = 2.7508, val loss = 2.7577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 33: 100%|██████████| 981/981 [09:56<00:00,  1.65it/s, loss=2.7250]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33: train loss = 2.7500, val loss = 2.7535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 34: 100%|██████████| 981/981 [09:33<00:00,  1.71it/s, loss=2.7619]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34: train loss = 2.7491, val loss = 2.7496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 35: 100%|██████████| 981/981 [09:37<00:00,  1.70it/s, loss=2.7623]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35: train loss = 2.7482, val loss = 2.7507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 36: 100%|██████████| 981/981 [09:33<00:00,  1.71it/s, loss=2.7467]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36: train loss = 2.7477, val loss = 2.7541\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 37: 100%|██████████| 981/981 [09:32<00:00,  1.71it/s, loss=2.7359]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37: train loss = 2.7472, val loss = 2.7504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 38: 100%|██████████| 981/981 [09:28<00:00,  1.72it/s, loss=2.7565]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38: train loss = 2.7464, val loss = 2.7510\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 39: 100%|██████████| 981/981 [09:31<00:00,  1.72it/s, loss=2.7701]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39: train loss = 2.7464, val loss = 2.7497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 40: 100%|██████████| 981/981 [09:31<00:00,  1.72it/s, loss=2.7367]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40: train loss = 2.7457, val loss = 2.7465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 41: 100%|██████████| 981/981 [09:33<00:00,  1.71it/s, loss=2.7368]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41: train loss = 2.7453, val loss = 2.7464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 42: 100%|██████████| 981/981 [09:33<00:00,  1.71it/s, loss=2.7366]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42: train loss = 2.7445, val loss = 2.7487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 43: 100%|██████████| 981/981 [09:32<00:00,  1.71it/s, loss=2.7343]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43: train loss = 2.7442, val loss = 2.7452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 44: 100%|██████████| 981/981 [09:36<00:00,  1.70it/s, loss=2.7575]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44: train loss = 2.7438, val loss = 2.7415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 45: 100%|██████████| 981/981 [09:35<00:00,  1.70it/s, loss=2.7550]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45: train loss = 2.7434, val loss = 2.7452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 46: 100%|██████████| 981/981 [09:34<00:00,  1.71it/s, loss=2.7379]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46: train loss = 2.7428, val loss = 2.7478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 47: 100%|██████████| 981/981 [09:33<00:00,  1.71it/s, loss=2.7412]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47: train loss = 2.7426, val loss = 2.7431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 48: 100%|██████████| 981/981 [09:32<00:00,  1.71it/s, loss=2.7640]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48: train loss = 2.7421, val loss = 2.7450\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 49: 100%|██████████| 981/981 [09:34<00:00,  1.71it/s, loss=2.7505]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49: train loss = 2.7415, val loss = 2.7388\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 100\n",
        "loss_train_col, loss_val_col = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    torch.cuda.empty_cache()\n",
        "    model.train().to(device)\n",
        "\n",
        "    batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n",
        "    total_loss, total_masked = 0.0, 0\n",
        "\n",
        "    for step, batch in enumerate(batch_iterator):\n",
        "        # -------- 1) Load batch --------\n",
        "        encoder_input = batch[\"encoder_input\"].to(device)   # (B, S)\n",
        "        encoder_mask  = batch[\"encoder_mask\"].to(device)    # (B, S), True=PAD\n",
        "        labels        = batch[\"label\"].to(device)           # (B, S)\n",
        "\n",
        "        # -------- 2) Forward --------\n",
        "        logits = model(encoder_input, src_key_padding_mask=encoder_mask)  # (B, S, V)\n",
        "\n",
        "        # -------- 3) Select only masked positions --------\n",
        "        masked_pos = (encoder_input == mask_id)             # (B, S) bool\n",
        "        num_masked = int(masked_pos.sum().item())\n",
        "        if num_masked == 0:\n",
        "            # No masked tokens in this batch; skip update to avoid NaNs\n",
        "            batch_iterator.set_postfix({\"loss\": \"skip (no [MASK])\"})\n",
        "            continue\n",
        "\n",
        "        # Flatten and index only masked positions\n",
        "        V = tokenizer.get_vocab_size()\n",
        "        logits_flat = logits.view(-1, V)                    # (B*S, V)\n",
        "        labels_flat = labels.view(-1)                       # (B*S,)\n",
        "        masked_idx  = masked_pos.view(-1)                   # (B*S,)\n",
        "\n",
        "        loss = loss_fn(logits_flat[masked_idx], labels_flat[masked_idx])  # sum over masked\n",
        "\n",
        "        # -------- 4) Backprop --------\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # -------- 5) Logging (average per masked token for the batch) --------\n",
        "        total_loss   += loss.item()\n",
        "        total_masked += num_masked\n",
        "        batch_iterator.set_postfix({\"loss\": f\"{(loss.item()/num_masked):.4f}\"})\n",
        "\n",
        "    # -------- 6) Epoch averages --------\n",
        "    ave_train_loss = total_loss / max(total_masked, 1)\n",
        "    ave_val_loss   = run_validation(model, val_dataloader, tokenizer, device, loss_fn, mask_id)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d}: train loss = {ave_train_loss:.4f}, val loss = {ave_val_loss:.4f}\")\n",
        "    loss_train_col.append(ave_train_loss)\n",
        "    loss_val_col.append(ave_val_loss)\n",
        "\n",
        "    # -------- 7) Checkpoint --------\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    }, f\"tmodel_{epoch:02d}.pt\")\n",
        "\n",
        "# -------- 8) Save losses --------\n",
        "df = pd.DataFrame({\"loss_train\": loss_train_col, \"loss_val\": loss_val_col})\n",
        "df.to_csv(\"_loss.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
